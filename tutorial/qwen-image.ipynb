{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bfae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.5.1+cu121)\n",
      "    Python  3.11.11 (you have 3.11.9)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "2025-08-22 11:35:26.218068: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-22 11:35:26.229879: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755830126.243857 4146818 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755830126.248051 4146818 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-22 11:35:26.262951: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The config attributes {'pooled_projection_dim': 768} were passed to QwenImageTransformer2DModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a357f6cc88b149789f3db827542af18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'pooled_projection_dim': 768} were passed to QwenImageTransformer2DModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5808236cfca94ac3a9fc3a1ba1824dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb56c0d2f47849d394401e66d220dd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "It seems like you have activated a device mapping strategy on the pipeline so calling `enable_sequential_cpu_offload() isn't allowed. You can call `reset_device_map()` first and then call `enable_sequential_cpu_offload()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m pipe\u001b[38;5;241m.\u001b[39menable_vae_slicing()         \u001b[38;5;66;03m# VAE slices\u001b[39;00m\n\u001b[1;32m     37\u001b[0m pipe\u001b[38;5;241m.\u001b[39menable_vae_tiling()          \u001b[38;5;66;03m# tiling helps larger resolutions\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_sequential_cpu_offload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# move modules to CPU between calls\u001b[39;00m\n\u001b[1;32m     40\u001b[0m positive_magic \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, just regular image\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# for english prompt\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzh\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, Ë∂ÖÊ∏ÖÔºå4KÔºåÁîµÂΩ±Á∫ßÊûÑÂõæ.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# for chinese prompt\u001b[39;00m\n\u001b[1;32m     43\u001b[0m }\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Generate image\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/anas_env/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:1295\u001b[0m, in \u001b[0;36mDiffusionPipeline.enable_sequential_cpu_offload\u001b[0;34m(self, gpu_id, device)\u001b[0m\n\u001b[1;32m   1293\u001b[0m is_pipeline_device_mapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_device_map) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_pipeline_device_mapped:\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt seems like you have activated a device mapping strategy on the pipeline so calling `enable_sequential_cpu_offload() isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt allowed. You can call `reset_device_map()` first and then call `enable_sequential_cpu_offload()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1297\u001b[0m     )\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1300\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device()\n",
      "\u001b[0;31mValueError\u001b[0m: It seems like you have activated a device mapping strategy on the pipeline so calling `enable_sequential_cpu_offload() isn't allowed. You can call `reset_device_map()` first and then call `enable_sequential_cpu_offload()`."
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen-Image\"\n",
    "\n",
    "# Load the pipeline\n",
    "if torch.cuda.is_available():\n",
    "    torch_dtype = torch.bfloat16\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    torch_dtype = torch.float32\n",
    "    device = \"cpu\"\n",
    "    \n",
    "# If your GPU has 24 GiB, 20/24 ~= 0.83\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_per_process_memory_fraction(0.83, device=0)  # soft cap; prevents allocator from growing past ~cap\n",
    "    \n",
    "# Ask diffusers/accelerate to stay within 20 GiB on GPU and spill the rest to CPU\n",
    "max_mem = {0: \"20GiB\", \"cpu\": \"64GiB\"}  # adjust CPU RAM as you like\n",
    "\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch_dtype, device_map=\"balanced\", max_memory=max_mem)\n",
    "\n",
    "\n",
    "# ----- 2) Turn on memory-saving knobs\n",
    "# Prefer SDPA (PyTorch 2.x) or xFormers if you have it\n",
    "try:\n",
    "    pipe.enable_sdpa()  # uses scaled-dot-product attention\n",
    "except Exception:\n",
    "    try:\n",
    "        pipe.enable_xformers_memory_efficient_attention()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "pipe.enable_attention_slicing()   # chunk attention\n",
    "pipe.enable_vae_slicing()         # VAE slices\n",
    "pipe.enable_vae_tiling()          # tiling helps larger resolutions\n",
    "# pipe.enable_sequential_cpu_offload()  # move modules to CPU between calls\n",
    "\n",
    "positive_magic = {\n",
    "    \"en\": \", just regular image\", # for english prompt\n",
    "    \"zh\": \", Ë∂ÖÊ∏ÖÔºå4KÔºåÁîµÂΩ±Á∫ßÊûÑÂõæ.\" # for chinese prompt\n",
    "}\n",
    "\n",
    "# Generate image\n",
    "prompt = '''A coffee shop entrance features a chalkboard sign reading \"Qwen Coffee üòä $2 per cup,\" with a neon light beside it displaying \"ÈÄö‰πâÂçÉÈóÆ\". Next to it hangs a poster showing a beautiful Chinese woman, and beneath the poster is written \"œÄ‚âà3.1415926-53589793-23846264-33832795-02384197\".'''\n",
    "\n",
    "negative_prompt = \" \" # Recommended if you don't use a negative prompt.\n",
    "\n",
    "# ----- 4) Resolution (keep moderate to reduce peak VRAM)\n",
    "width, height = (1664, 928)  # 16:9; lowering this saves a lot of memory\n",
    "\n",
    "# ----- 5) CFG can increase memory (second UNet pass). If you hit OOM, set to 1.0 (no CFG).\n",
    "true_cfg_scale = 4.0  # try 1.0 if you still exceed ~20 GiB\n",
    "\n",
    "gen = torch.Generator(device=\"cuda\") if torch.cuda.is_available() else torch.Generator()\n",
    "gen = gen.manual_seed(42)\n",
    "\n",
    "\n",
    "# Generate with different aspect ratios\n",
    "aspect_ratios = {\n",
    "    \"1:1\": (1328, 1328),\n",
    "    \"16:9\": (1664, 928),\n",
    "    \"9:16\": (928, 1664),\n",
    "    \"4:3\": (1472, 1104),\n",
    "    \"3:4\": (1104, 1472),\n",
    "    \"3:2\": (1584, 1056),\n",
    "    \"2:3\": (1056, 1584),\n",
    "}\n",
    "\n",
    "width, height = aspect_ratios[\"16:9\"]\n",
    "\n",
    "image = pipe(\n",
    "    prompt=prompt + positive_magic[\"en\"],\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    num_inference_steps=50,\n",
    "    true_cfg_scale=true_cfg_scale,\n",
    "    generator=gen\n",
    ").images[0]\n",
    "\n",
    "image.save(\"example.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anas_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
